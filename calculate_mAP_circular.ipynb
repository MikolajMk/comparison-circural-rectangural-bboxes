{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script lets user to calculate mAP for circular bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all lib\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions needed to load and process data. They are described in script about final model for cicular bboxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Usefull functions\n",
    "\n",
    "def create_df(path_annotations_circle):\n",
    "    all_files = glob.glob(path_annotations_circle + \"\\\\*.csv\")\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    df_circle = df[['name', 'c-x', 'c-y', 'radius']]\n",
    "\n",
    "    return df_circle\n",
    "\n",
    "def get_max_number(df_circle):\n",
    "    value = df_circle.groupby('name').agg('count').sort_values('radius', ascending=False).max()[['radius']].tolist()\n",
    "    return value[0]\n",
    "\n",
    "def get_bbox_cords(df_circle):\n",
    "    gb = df_circle.groupby('name')    \n",
    "    gb = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "\n",
    "    list =[]\n",
    "    for set_of_df in gb:\n",
    "        lista = []\n",
    "        for i in range(18*3):\n",
    "            if str(set_of_df['radius'].values.tolist()[0]) == 'nan':\n",
    "                lista.append(0)\n",
    "            else:\n",
    "                lista = set_of_df[['c-x','c-y','radius']].stack().tolist()\n",
    "                number = 54 - len(lista)\n",
    "                a = [0]*number\n",
    "                lista = lista + a\n",
    "                break\n",
    "        list.append(lista)\n",
    "\n",
    "    return list\n",
    "\n",
    "def get_bbox_cords_to_dict(df_circle):\n",
    "    gb = df_circle.groupby('name')    \n",
    "    gb = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "    dict = {}\n",
    "    list =[]\n",
    "    for set_of_df in gb:\n",
    "        name = (set_of_df['name'].values.tolist()[0].replace('.csv', ''))\n",
    "        lista = []\n",
    "        for i in range(18*3):\n",
    "            if str(set_of_df['radius'].values.tolist()[0]) == 'nan':\n",
    "                lista.append(0)\n",
    "            else:\n",
    "                lista = set_of_df[['c-x','c-y','radius']].stack().tolist()\n",
    "                number = 54 - len(lista)\n",
    "                a = [0]*number\n",
    "                lista = lista + a\n",
    "                break\n",
    "        list.append(lista)\n",
    "        dict.update({name:lista})\n",
    "\n",
    "\n",
    "\n",
    "    return dict\n",
    "\n",
    "def get_image_data(imagespath):\n",
    "  path = glob.glob(imagespath + '\\\\*.png')\n",
    "  images=[cv2.imread(file) for file in path]\n",
    "  return images\n",
    "\n",
    "\n",
    "def apply_threshold_and_split_pred(trainprediction, thresh):\n",
    "    prediction = []\n",
    "    three_coord_list = []\n",
    "    iter = 0\n",
    "    prediction_threshold = trainprediction\n",
    "\n",
    "    for i in range(len(prediction_threshold[0])):\n",
    "        if prediction_threshold[0][i] < thresh:\n",
    "            prediction_threshold[0][i] = 0\n",
    "\n",
    "    for elem in prediction_threshold[0]:\n",
    "        if iter < 3:\n",
    "            three_coord_list.append(elem)\n",
    "            iter +=1\n",
    "        else:\n",
    "            iter = 1\n",
    "            prediction.append(three_coord_list)\n",
    "            three_coord_list = []\n",
    "            three_coord_list.append(elem)\n",
    "    prediction.append(three_coord_list)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def split_origin(origin_img):\n",
    "    origin = []\n",
    "    three_coord_list = []\n",
    "    iter = 0\n",
    "\n",
    "    for elem in origin_img:\n",
    "        if iter < 3:\n",
    "            three_coord_list.append(elem)\n",
    "            iter +=1\n",
    "        else:\n",
    "            iter = 1\n",
    "            origin.append(three_coord_list)\n",
    "            three_coord_list = []\n",
    "            three_coord_list.append(elem)\n",
    "    origin.append(three_coord_list)\n",
    "\n",
    "    return origin\n",
    "\n",
    "def draw_circle(ax, Color, coords):\n",
    "    for elem in coords:\n",
    "        x = float(elem[0])\n",
    "        y = float(elem[1])\n",
    "        radius = float(elem[2])\n",
    "        circ = Circle((x,y),radius, fill=False, color = Color)\n",
    "        ax.add_patch(circ)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_results(img, prediction, original_coords):\n",
    "\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(img, interpolation='nearest')\n",
    "\n",
    "    ax = draw_circle(ax, 'Red', prediction)\n",
    "    ax = draw_circle(ax, 'Blue', original_coords)\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "def calculate_iou(prediction, original_coords):\n",
    "    iter = 0 \n",
    "    iou_list = []\n",
    "    for pred_elem, original_elem in zip(prediction,original_coords):\n",
    "        iter +=1\n",
    "        c1_x = pred_elem[0]\n",
    "        c1_y = pred_elem[1] \n",
    "        r1 = pred_elem[2] \n",
    "        c2_x = original_elem[0]\n",
    "        c2_y = original_elem[1]\n",
    "        r2 = original_elem[2]\n",
    "\n",
    "        if c2_x == 0 and c2_y == 0 and r2 == 0:\n",
    "            iou = 'NoOriginObject'\n",
    "        else:\n",
    "            distance = np.sqrt((c1_x - c2_x)**2 + (c1_y - c2_y)**2)\n",
    "            \n",
    "            if distance > r1 + r2:\n",
    "                return 0.0\n",
    "            elif (distance <= (r1 - r2) and r1 >= r2):\n",
    "                intersection_area = np.pi * r2 * r2\n",
    "        \n",
    "            elif (distance <= (r2 - r1) and r2 >= r1):\n",
    "                intersection_area = np.pi * r1 * r1\n",
    "        \n",
    "            else :\n",
    "                alpha = np.arccos(((r1 * r1) + (distance * distance) - (r2 * r2)) / (2 * r1 * distance)) * 2\n",
    "                beta = np.arccos(((r2 * r2) + (distance * distance) - (r1 * r1)) / (2 * r2 * distance)) * 2\n",
    "                \n",
    "                a1 = (0.5 * beta * r2 * r2 ) - (0.5 * r2 * r2 * np.sin(beta))\n",
    "                a2 = (0.5 * alpha * r1 * r1) - (0.5 * r1 * r1 * np.sin(alpha))\n",
    "                intersection_area = a1 + a2\n",
    "                \n",
    "            area1 = np.pi * r1**2\n",
    "            area2 = np.pi * r2**2\n",
    "\n",
    "            union_area = area1 + area2 - intersection_area\n",
    "                \n",
    "            iou = intersection_area / union_area\n",
    "\n",
    "        iou_list.append(iou)\n",
    "        print(f'{iter}: Original: {original_elem} | Predicted: {pred_elem} | IOU: {iou}')\n",
    "\n",
    "    return iou_list\n",
    "\n",
    "def calculate_iou_with_probability(prediction, original_coords, probability):\n",
    "    iter = 0 \n",
    "    i = 0\n",
    "    iou_list = []\n",
    "    for pred_elem, original_elem in zip(prediction,original_coords):\n",
    "        iter +=1\n",
    "        c1_x = pred_elem[0]\n",
    "        c1_y = pred_elem[1] \n",
    "        r1 = pred_elem[2] \n",
    "        c2_x = original_elem[0]\n",
    "        c2_y = original_elem[1]\n",
    "        r2 = original_elem[2]\n",
    "\n",
    "        if c2_x == 0 and c2_y == 0 and r2 == 0:\n",
    "            iou = 'NoOriginObject'\n",
    "        else:\n",
    "            distance = np.sqrt((c1_x - c2_x)**2 + (c1_y - c2_y)**2)\n",
    "            \n",
    "            if distance > r1 + r2:\n",
    "                return 0.0\n",
    "            elif (distance <= (r1 - r2) and r1 >= r2):\n",
    "                intersection_area = np.pi * r2 * r2\n",
    "        \n",
    "            elif (distance <= (r2 - r1) and r2 >= r1):\n",
    "                intersection_area = np.pi * r1 * r1\n",
    "        \n",
    "            else :\n",
    "                alpha = np.arccos(((r1 * r1) + (distance * distance) - (r2 * r2)) / (2 * r1 * distance)) * 2\n",
    "                beta = np.arccos(((r2 * r2) + (distance * distance) - (r1 * r1)) / (2 * r2 * distance)) * 2\n",
    "                \n",
    "                a1 = (0.5 * beta * r2 * r2 ) - (0.5 * r2 * r2 * np.sin(beta))\n",
    "                a2 = (0.5 * alpha * r1 * r1) - (0.5 * r1 * r1 * np.sin(alpha))\n",
    "                intersection_area = a1 + a2\n",
    "                \n",
    "            area1 = np.pi * r1**2\n",
    "            area2 = np.pi * r2**2\n",
    "\n",
    "            union_area = area1 + area2 - intersection_area\n",
    "                \n",
    "            iou = intersection_area / union_area\n",
    "\n",
    "        iou_list.append(iou)\n",
    "        print(f'{iter}: Original: {original_elem} | Predicted: {pred_elem} | Probability: {round(float(probability[0][iter-1]), 3)} | IOU: {iou}')\n",
    "        i = i + 1\n",
    "\n",
    "    return iou_list\n",
    "\n",
    "def calculate_prob(list_of_coords):\n",
    "    probability = []\n",
    "    list_of_prob = []\n",
    "    for set_ in list_of_coords:\n",
    "        lst = set_[::3]\n",
    "        for value in lst:\n",
    "            if value != 0:\n",
    "                probability.append(1)\n",
    "            else:\n",
    "                probability.append(0)\n",
    "        list_of_prob.append(probability)\n",
    "        probability = []\n",
    "    \n",
    "    return list_of_prob\n",
    "\n",
    "def dataset_shuffle(images,list_of_prob,list_of_coords,bool):\n",
    "    if bool == True:\n",
    "        whole_set = []\n",
    "        for img, prob, coord in zip(images,list_of_prob ,list_of_coords):\n",
    "            one_set = []\n",
    "            one_set.append(img)\n",
    "            one_set.append(prob)\n",
    "            one_set.append(coord)\n",
    "            whole_set.append(one_set)\n",
    "\n",
    "        shuffle(whole_set)\n",
    "        img_sh = []\n",
    "        prob_sh =[]\n",
    "        coord_sh = []\n",
    "\n",
    "        for set_ in whole_set:\n",
    "            img_sh.append(set_[0])\n",
    "            prob_sh.append(set_[1])\n",
    "            coord_sh.append(set_[2])\n",
    "\n",
    "        return img_sh, prob_sh, coord_sh\n",
    "    else:\n",
    "        return images, list_of_prob, list_of_coords\n",
    "\n",
    "def reverse_transform_data_only_coords(data, grid_size):\n",
    "    image_height, image_width = 202, 308\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "    \n",
    "    coords_final = []\n",
    "\n",
    "    for batch_data in data.reshape((-1, grid_size[0] * grid_size[1], 3)):\n",
    "        batch_coords = []\n",
    "\n",
    "        for y in range(grid_size[0]):\n",
    "            for x in range(grid_size[1]):\n",
    "                local_x, local_y, r = batch_data[y * grid_size[1] + x]  \n",
    "                global_x = x * cell_width + local_x\n",
    "                global_y = y * cell_height + local_y\n",
    "                \n",
    "                batch_coords.extend([global_x, global_y, r])\n",
    "\n",
    "        coords_final.append(batch_coords)\n",
    "\n",
    "    return coords_final\n",
    "\n",
    "def reverse_transform_deep_nested_coords(batch_data, grid_size, max_box_per_apple=2):\n",
    "    image_height, image_width = 202, 308\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "\n",
    "    output_list = []\n",
    "\n",
    "    for y in range(grid_size[0]):\n",
    "        for x in range(grid_size[1]):\n",
    "\n",
    "            if max_box_per_apple == 2:\n",
    "                local_coords1 = batch_data[0][y][x][0]\n",
    "                local_coords2 = batch_data[0][y][x][1]\n",
    "                \n",
    "                global_x1 = x * cell_width + local_coords1[0]\n",
    "                global_y1 = y * cell_height + local_coords1[1]\n",
    "                \n",
    "                global_x2 = x * cell_width + local_coords2[0]\n",
    "                global_y2 = y * cell_height + local_coords2[1]\n",
    "                \n",
    "                output_list.append(global_x1)\n",
    "                output_list.append(global_y1)\n",
    "                output_list.append(local_coords1[2])\n",
    "                output_list.append(global_x2)\n",
    "                output_list.append(global_y2)\n",
    "                output_list.append(local_coords2[2])\n",
    "            elif max_box_per_apple == 1:\n",
    "                local_coords1 = batch_data[0][y][x][0]\n",
    "                \n",
    "                global_x1 = x * cell_width + local_coords1[0]\n",
    "                global_y1 = y * cell_height + local_coords1[1]\n",
    "                \n",
    "                output_list.append(global_x1)\n",
    "                output_list.append(global_y1)\n",
    "                output_list.append(local_coords1[2])\n",
    "\n",
    "\n",
    "    return np.array(output_list)\n",
    "    \n",
    "def reverse_transform_deep_nested_coords_and_normalization(batch_data, grid_size, max_box_per_apple=2):\n",
    "    image_height, image_width = 202, 308\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "    cell_diagonal = math.sqrt(cell_height**2+cell_width**2)\n",
    "    \n",
    "    output_list = []\n",
    "\n",
    "    for y in range(grid_size[0]):\n",
    "        for x in range(grid_size[1]):\n",
    "\n",
    "            if max_box_per_apple == 2:\n",
    "                local_coords1 = batch_data[0][y][x][0]\n",
    "                local_coords2 = batch_data[0][y][x][1]\n",
    "                \n",
    "                global_x1 = x * cell_width + local_coords1[0] * cell_width\n",
    "                global_y1 = y * cell_height + local_coords1[1] * cell_height\n",
    "                \n",
    "                global_x2 = x * cell_width + local_coords2[0] * cell_width\n",
    "                global_y2 = y * cell_height + local_coords2[1] * cell_height\n",
    "                \n",
    "                output_list.append(global_x1)\n",
    "                output_list.append(global_y1)\n",
    "                output_list.append(local_coords1[2] * cell_diagonal)\n",
    "                output_list.append(global_x2)\n",
    "                output_list.append(global_y2)\n",
    "                output_list.append(local_coords2[2] * cell_diagonal)\n",
    "            elif max_box_per_apple == 1:\n",
    "                local_coords1 = batch_data[0][y][x][0]\n",
    "                \n",
    "                global_x1 = x * cell_width + local_coords1[0] * cell_width\n",
    "                global_y1 = y * cell_height + local_coords1[1] * cell_height\n",
    "                \n",
    "                output_list.append(global_x1)\n",
    "                output_list.append(global_y1)\n",
    "                output_list.append(local_coords1[2] * cell_diagonal)\n",
    "\n",
    "\n",
    "    return np.array(output_list)\n",
    "\n",
    "def Iou(prediction, original_coords):\n",
    "    iter = 0 \n",
    "    iou_list = []\n",
    "    for pred_elem, original_elem in zip(prediction,original_coords):\n",
    "        iter +=1\n",
    "        c1_x = pred_elem[0]\n",
    "        c1_y = pred_elem[1] \n",
    "        r1 = pred_elem[2] \n",
    "        c2_x = original_elem[0]\n",
    "        c2_y = original_elem[1]\n",
    "        r2 = original_elem[2]\n",
    "\n",
    "        if c2_x == 0 and c2_y == 0 and r2 == 0:\n",
    "            iou = -1\n",
    "        else:\n",
    "            distance = np.sqrt((c1_x - c2_x)**2 + (c1_y - c2_y)**2)\n",
    "            \n",
    "            if distance > r1 + r2:\n",
    "                return [0.0]\n",
    "            elif (distance <= (r1 - r2) and r1 >= r2):\n",
    "                intersection_area = np.pi * r2 * r2\n",
    "        \n",
    "            elif (distance <= (r2 - r1) and r2 >= r1):\n",
    "                intersection_area = np.pi * r1 * r1\n",
    "        \n",
    "            else :\n",
    "                alpha = np.arccos(((r1 * r1) + (distance * distance) - (r2 * r2)) / (2 * r1 * distance)) * 2\n",
    "                beta = np.arccos(((r2 * r2) + (distance * distance) - (r1 * r1)) / (2 * r2 * distance)) * 2\n",
    "                \n",
    "                a1 = (0.5 * beta * r2 * r2 ) - (0.5 * r2 * r2 * np.sin(beta))\n",
    "                a2 = (0.5 * alpha * r1 * r1) - (0.5 * r1 * r1 * np.sin(alpha))\n",
    "                intersection_area = a1 + a2\n",
    "                \n",
    "            area1 = np.pi * r1**2\n",
    "            area2 = np.pi * r2**2\n",
    "\n",
    "            union_area = area1 + area2 - intersection_area\n",
    "                \n",
    "            iou = intersection_area / union_area\n",
    "\n",
    "        iou_list.append(iou)\n",
    "\n",
    "    return iou_list\n",
    "\n",
    "def NMS(pred, iou_threshold, prob_threshold, prob):\n",
    "\n",
    "    one_box = []\n",
    "    predictions_with_prob =[]\n",
    "    iter = 0\n",
    "    iter_prob = 0\n",
    "    for elem in pred:\n",
    "        if iter == 2:\n",
    "            iter = 0\n",
    "            one_box.append(elem)\n",
    "            one_box.append(prob[iter_prob])\n",
    "            iter_prob += 1\n",
    "            predictions_with_prob.append(one_box)\n",
    "            one_box = []\n",
    "        else:\n",
    "            one_box.append(elem)\n",
    "            iter += 1\n",
    "\n",
    "    bbox_list_thresholded = []\n",
    "    bbox_list_new = []\n",
    "\n",
    "    box_sorted = sorted(predictions_with_prob, reverse=True, key = lambda x :x[3])\n",
    "\n",
    "    for box in box_sorted:\n",
    "        if box[3] > prob_threshold:\n",
    "            bbox_list_thresholded.append(box)\n",
    "\n",
    "    while len(bbox_list_thresholded) > 0:\n",
    "        current_box = bbox_list_thresholded.pop(0)\n",
    "        bbox_list_new.append(current_box)\n",
    "        for box in bbox_list_thresholded:\n",
    "            iou = Iou([current_box[:3]], [box[:3]])\n",
    "            if iou[0] > iou_threshold:\n",
    "                bbox_list_thresholded.remove(box)\n",
    "\n",
    "    return bbox_list_new\n",
    "\n",
    "def transform_data(coords, probs, grid_size, max_apples_per_cell=2):\n",
    "    image_height, image_width = 202, 308\n",
    "    \n",
    "    transformed_coords_final = []\n",
    "    transformed_probs_final = []\n",
    "\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        transformed_coords = np.zeros((grid_size[0], grid_size[1], max_apples_per_cell, 3))\n",
    "        transformed_probs = np.zeros((grid_size[0], grid_size[1], max_apples_per_cell, 1))\n",
    "\n",
    "        apple_counter = np.zeros((grid_size[0], grid_size[1]), dtype=int)\n",
    "\n",
    "        for j in range(len(probs[0])):\n",
    "            if probs[i][j] == 1:  \n",
    "                x, y, r = coords[i][j*3:j*3+3]\n",
    "\n",
    "                if x == image_width and y == image_height:\n",
    "                    cell_x = 3\n",
    "                    cell_y = 3\n",
    "                elif x == image_width:\n",
    "                    cell_x = 3\n",
    "                    cell_y = int(np.floor(y // cell_height))\n",
    "                elif y == image_height:\n",
    "                    cell_x = int(np.floor(x // cell_width))\n",
    "                    cell_y = 3\n",
    "                else:\n",
    "                    cell_x, cell_y = int(np.floor(x // cell_width)), int(np.floor(y // cell_height))\n",
    "                \n",
    "                local_x = (x % cell_width)\n",
    "                local_y = (y % cell_height)\n",
    "                \n",
    "                if apple_counter[cell_y, cell_x] < max_apples_per_cell:\n",
    "                    idx = apple_counter[cell_y, cell_x]\n",
    "                    transformed_coords[cell_y, cell_x, idx] = [local_x, local_y, r]\n",
    "                    transformed_probs[cell_y, cell_x, idx] = [1]  \n",
    "                    \n",
    "                    apple_counter[cell_y, cell_x] += 1\n",
    "\n",
    "                   \n",
    "        transformed_coords = transformed_coords.tolist()\n",
    "        transformed_probs = transformed_probs.tolist()\n",
    "\n",
    "        transformed_coords_final.append(transformed_coords)\n",
    "        transformed_probs_final.append(transformed_probs)\n",
    "\n",
    "    return transformed_coords_final, transformed_probs_final\n",
    "\n",
    "def transform_data_and_normalize(coords, probs, grid_size, max_apples_per_cell=2):\n",
    "    image_height, image_width = 202, 308\n",
    "    \n",
    "    transformed_coords_final = []\n",
    "    transformed_probs_final = []\n",
    "\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "    cell_diagonal = math.sqrt(cell_height**2+cell_width**2)\n",
    "\n",
    "    for i in range(len(probs)):\n",
    "        transformed_coords = np.zeros((grid_size[0], grid_size[1], max_apples_per_cell, 3))\n",
    "        transformed_probs = np.zeros((grid_size[0], grid_size[1], max_apples_per_cell, 1))\n",
    "\n",
    "        apple_counter = np.zeros((grid_size[0], grid_size[1]), dtype=int)\n",
    "\n",
    "        for j in range(len(probs[0])):\n",
    "            if probs[i][j] == 1:  \n",
    "                x, y, r = coords[i][j*3:j*3+3]\n",
    "\n",
    "                if x == image_width and y == image_height:\n",
    "                    cell_x = 3\n",
    "                    cell_y = 3\n",
    "                elif x == image_width:\n",
    "                    cell_x = 3\n",
    "                    cell_y = int(np.floor(y // cell_height))\n",
    "                elif y == image_height:\n",
    "                    cell_x = int(np.floor(x // cell_width))\n",
    "                    cell_y = 3\n",
    "                else:\n",
    "                    cell_x, cell_y = int(np.floor(x // cell_width)), int(np.floor(y // cell_height))\n",
    "                \n",
    "                local_x = (x % cell_width)\n",
    "                local_y = (y % cell_height)\n",
    "                \n",
    "                if apple_counter[cell_y, cell_x] < max_apples_per_cell:\n",
    "\n",
    "                    idx = apple_counter[cell_y, cell_x]\n",
    "                    transformed_coords[cell_y, cell_x, idx] = [local_x / cell_width, local_y / cell_height, r / cell_diagonal]\n",
    "                    transformed_probs[cell_y, cell_x, idx] = [1]  \n",
    "                    \n",
    "                    apple_counter[cell_y, cell_x] += 1\n",
    "\n",
    "                   \n",
    "        transformed_coords = transformed_coords.tolist()\n",
    "        transformed_probs = transformed_probs.tolist()\n",
    "\n",
    "        transformed_coords_final.append(transformed_coords)\n",
    "        transformed_probs_final.append(transformed_probs)\n",
    "\n",
    "    return transformed_coords_final, transformed_probs_final\n",
    "\n",
    "def reverse_transform_data(data, grid_size):\n",
    "    image_height, image_width = 202, 308\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "    \n",
    "    coords_final = []\n",
    "    probs_final = []\n",
    "\n",
    "    for batch_data in data:\n",
    "        batch_coords = []\n",
    "        batch_probs = []\n",
    "\n",
    "        for y in range(grid_size[0]):\n",
    "            for x in range(grid_size[1]):\n",
    "                for apple_data in batch_data[y][x]:\n",
    "                    local_x, local_y, r, prob = apple_data\n",
    "\n",
    "\n",
    "                    global_x = x * cell_width + local_x\n",
    "                    global_y = y * cell_height + local_y\n",
    "                    \n",
    "                    batch_coords.extend([global_x, global_y, r])\n",
    "                    batch_probs.append(prob)  \n",
    "\n",
    "        coords_final.append(batch_coords)\n",
    "        probs_final.append(batch_probs)\n",
    "\n",
    "    return coords_final, probs_final\n",
    "\n",
    "def reverse_transform_data_and_normalization(data, grid_size):\n",
    "    image_height, image_width = 202, 308\n",
    "    cell_height, cell_width = image_height / grid_size[0], image_width / grid_size[1]\n",
    "    cell_diagonal = math.sqrt(cell_height**2+cell_width**2)\n",
    "\n",
    "    coords_final = []\n",
    "    probs_final = []\n",
    "\n",
    "    for batch_data in data:\n",
    "        batch_coords = []\n",
    "        batch_probs = []\n",
    "\n",
    "        for y in range(grid_size[0]):\n",
    "            for x in range(grid_size[1]):\n",
    "                for apple_data in batch_data[y][x]:\n",
    "                    local_x, local_y, r, prob = apple_data\n",
    "\n",
    "\n",
    "                    global_x = x * cell_width + local_x * cell_width\n",
    "                    global_y = y * cell_height + local_y * cell_height\n",
    "                    global_r = r * cell_diagonal\n",
    "                    \n",
    "                    batch_coords.extend([global_x, global_y, global_r])\n",
    "                    batch_probs.append(prob)  \n",
    "\n",
    "        coords_final.append(batch_coords)\n",
    "        probs_final.append(batch_probs)\n",
    "\n",
    "    return coords_final, probs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions needed to caluclate mAP values for circular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Intersection over Union (IoU) for a single prediction and ground truth pair.\n",
    "def Iou_One_Val(pred_elem, original_elem):\n",
    "    # Extract prediction coordinates and radius\n",
    "    c1_x, c1_y, r1 = pred_elem\n",
    "    # Extract ground truth coordinates and radius\n",
    "    c2_x, c2_y, r2 = original_elem\n",
    "\n",
    "    # Check if the ground truth circle is a \"don't care\" condition (0,0,0)\n",
    "    if c2_x == 0 and c2_y == 0 and r2 == 0:\n",
    "        return -1  # Special case for \"don't care\"\n",
    "\n",
    "    # Check if the prediction and ground truth circles are identical\n",
    "    if c1_x == c2_x and c1_y == c2_y and r1 == r2:\n",
    "        return 1  # The prediction and ground truth are identical\n",
    "\n",
    "    # Calculate the distance between the centers of the circles\n",
    "    distance = np.sqrt((c1_x - c2_x) ** 2 + (c1_y - c2_y) ** 2)\n",
    "\n",
    "    # Case 1: Circles do not intersect\n",
    "    if distance > r1 + r2:\n",
    "        return 0.0\n",
    "    # Case 2: One circle is entirely within the other\n",
    "    elif (distance <= (r1 - r2) and r1 >= r2):\n",
    "        # Intersection area is the area of the smaller circle\n",
    "        intersection_area = np.pi * r2 * r2\n",
    "    elif (distance <= (r2 - r1) and r2 >= r1):\n",
    "        # Intersection area is the area of the smaller circle\n",
    "        intersection_area = np.pi * r1 * r1\n",
    "    else:\n",
    "        # Case 3: Partial overlap of circles\n",
    "        # Calculate angles alpha and beta\n",
    "        alpha = np.arccos(((r1 * r1) + (distance * distance) - (r2 * r2)) / (2 * r1 * distance)) * 2\n",
    "        beta = np.arccos(((r2 * r2) + (distance * distance) - (r1 * r1)) / (2 * r2 * distance)) * 2\n",
    "         \n",
    "        # Calculate intersection areas of segments and subtract from sector areas\n",
    "        a1 = (0.5 * beta * r2 * r2 ) - (0.5 * r2 * r2 * np.sin(beta))\n",
    "        a2 = (0.5 * alpha * r1 * r1) - (0.5 * r1 * r1 * np.sin(alpha))\n",
    "        intersection_area = a1 + a2\n",
    "        \n",
    "    # Calculate areas of the two circles\n",
    "    area1 = np.pi * r1 ** 2\n",
    "    area2 = np.pi * r2 ** 2\n",
    "\n",
    "    # Calculate the union area\n",
    "    union_area = area1 + area2 - intersection_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    return intersection_area / union_area\n",
    "\n",
    "\n",
    "# Function to calculate precision and recall at different IoU thresholds.\n",
    "def calculate_precision_recall_at_iou(ground_truths, predictions, iou_thresholds):\n",
    "    # Initialize dictionaries to store precisions and recalls for each IoU threshold\n",
    "    all_precisions = {iou_thresh: [] for iou_thresh in iou_thresholds}\n",
    "    all_recalls = {iou_thresh: [] for iou_thresh in iou_thresholds}\n",
    "\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        tp = 0  # True Positives\n",
    "        fp = 0  # False Positives\n",
    "        fn = len(ground_truths)  # False Negatives\n",
    "        empty_gt_count = sum(1 for gt in ground_truths if gt == [0, 0, 0])\n",
    "        temp_ground_truths = [gt for gt in ground_truths if gt != [0, 0, 0]]\n",
    "\n",
    "        for pred in predictions:\n",
    "            best_iou = -1\n",
    "            best_gt = None\n",
    "            # Find the ground truth with the highest IoU for each prediction\n",
    "            for gt in temp_ground_truths:\n",
    "                iou = Iou_One_Val(pred, gt)\n",
    "                if iou != -1 and iou >= best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt = gt\n",
    "\n",
    "            # If IoU exceeds the threshold, it's a True Positive\n",
    "            if best_iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                temp_ground_truths.remove(best_gt)\n",
    "\n",
    "        # Calculate False Negatives and False Positives\n",
    "        fn = fn - tp - empty_gt_count\n",
    "        fp = len(predictions) - tp\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        # Store precision and recall for the current IoU threshold\n",
    "        for iou_thresh in iou_thresholds:\n",
    "            all_precisions[iou_thresh].append(precision)\n",
    "            all_recalls[iou_thresh].append(recall)\n",
    "\n",
    "    # Return dictionaries of precisions and recalls for all IoU thresholds\n",
    "    return all_precisions, all_recalls\n",
    "\n",
    "\n",
    "# Function to calculate the average precision (AP) for a given set of precision and recall values.\n",
    "def calculate_ap(precisions, recalls):\n",
    "    # Sort recalls in ascending order\n",
    "    sort_order = np.argsort(recalls)\n",
    "    sorted_recalls = np.array(recalls)[sort_order]\n",
    "    sorted_precisions = np.array(precisions)[sort_order]\n",
    "\n",
    "    # Add endpoints to the recall and precision lists\n",
    "    sorted_recalls = np.concatenate(([0.0], sorted_recalls, [1.0]))\n",
    "    sorted_precisions = np.concatenate(([0.0], sorted_precisions, [0.0]))\n",
    "\n",
    "    # For each recall point, keep the highest precision\n",
    "    for i in range(len(sorted_precisions) - 2, -1, -1):\n",
    "        sorted_precisions[i] = max(sorted_precisions[i], sorted_precisions[i + 1])\n",
    "\n",
    "    # Calculate AP as the sum of recall differences multiplied by precision\n",
    "    ap = 0.0\n",
    "    for i in range(1, len(sorted_recalls)):\n",
    "        ap += ((sorted_recalls[i] - sorted_recalls[i - 1]) * sorted_precisions[i])\n",
    "\n",
    "    # Return the calculated Average Precision\n",
    "    return ap\n",
    "\n",
    "\n",
    "# Function to calculate the mean average precision (mAP) over a dataset at different IoU thresholds.\n",
    "def mean_average_precision(dataset, iou_thresholds=np.arange(0.5, 1.0, 0.05)):\n",
    "    map_values = []\n",
    "\n",
    "    for ground_truths, predictions in dataset:\n",
    "        # Calculate precision and recall at different IoU thresholds\n",
    "        precisions, recalls = calculate_precision_recall_at_iou(ground_truths, predictions, iou_thresholds)\n",
    "        ap_values = []\n",
    "        for iou_threshold in iou_thresholds:\n",
    "            # Calculate AP for each IoU threshold\n",
    "            ap = calculate_ap(precisions[iou_threshold], recalls[iou_threshold])\n",
    "            ap_values.append(ap)\n",
    "\n",
    "        # Calculate mean AP across IoU thresholds\n",
    "        map_values.append(np.mean(ap_values))\n",
    "\n",
    "    # Calculate the mean mAP over the entire dataset\n",
    "    mean_map = np.mean(map_values)\n",
    "    return mean_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and apply preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path for each dataset\n",
    "path_img_test = r'datasets_splited\\dataset_3\\test_aug\\images'\n",
    "path_csv_test = r'datasets_splited\\dataset_3\\test_aug\\annotations'\n",
    "\n",
    "path_img_train = r'datasets_splited\\dataset_3\\train_aug\\images'\n",
    "path_csv_train = r'datasets_splited\\dataset_3\\train_aug\\annotations'\n",
    "\n",
    "path_img_val = r'datasets_splited\\dataset_3\\val_aug\\images'\n",
    "path_csv_val = r'datasets_splited\\dataset_3\\val_aug\\annotations'\n",
    "\n",
    "# Define grid size\n",
    "grid_size = (7,10)\n",
    "\n",
    "\n",
    "#Functions invocation\n",
    "df_circle_test = create_df(path_csv_test)\n",
    "list_of_coords_test = get_bbox_cords(df_circle_test)\n",
    "images_test = get_image_data(path_img_test)\n",
    "list_of_prob_test = calculate_prob(list_of_coords_test)\n",
    "\n",
    "df_circle_train = create_df(path_csv_train)\n",
    "list_of_coords_train = get_bbox_cords(df_circle_train)\n",
    "images_train = get_image_data(path_img_train)\n",
    "list_of_prob_train = calculate_prob(list_of_coords_train)\n",
    "\n",
    "df_circle_val = create_df(path_csv_val)\n",
    "list_of_coords_val = get_bbox_cords(df_circle_val)\n",
    "images_val = get_image_data(path_img_val)\n",
    "list_of_prob_val = calculate_prob(list_of_coords_val)\n",
    "\n",
    "# Split data into cells and normalize coords\n",
    "transformed_coords_test, transformed_probs_test = transform_data_and_normalize(list_of_coords_test, list_of_prob_test, grid_size,max_apples_per_cell=1)\n",
    "transformed_coords_train, transformed_probs_train = transform_data_and_normalize(list_of_coords_train, list_of_prob_train, grid_size,max_apples_per_cell=1)\n",
    "transformed_coords_val, transformed_probs_val = transform_data_and_normalize(list_of_coords_val, list_of_prob_val, grid_size,max_apples_per_cell=1)\n",
    "\n",
    "# Normalize images\n",
    "for i in range(len(images_test)):\n",
    "    images_test[i] = images_test[i] / 255\n",
    "\n",
    "for i in range(len(images_train)):\n",
    "    images_train[i] = images_train[i] / 255\n",
    "\n",
    "for i in range(len(images_val)):\n",
    "    images_val[i] = images_val[i] / 255\n",
    "\n",
    "#Inserting data into numpy arrays and splitting to train and test set\n",
    "test_set_coords = np.array(transformed_coords_test)\n",
    "test_set_img = np.array(images_test)\n",
    "test_set_prob = transformed_probs_test\n",
    "\n",
    "train_set_coords = np.array(transformed_coords_train)\n",
    "train_set_img = np.array(images_train)\n",
    "train_set_prob = transformed_probs_train\n",
    "\n",
    "valid_set_coords = np.array(transformed_coords_val)\n",
    "valid_set_img = np.array(images_val)\n",
    "valid_set_prob = transformed_probs_val\n",
    "\n",
    "# Memory release\n",
    "del df_circle_test\n",
    "del list_of_coords_test\n",
    "del images_test \n",
    "del list_of_prob_test \n",
    "\n",
    "del df_circle_train \n",
    "del list_of_coords_train \n",
    "del images_train \n",
    "del list_of_prob_train \n",
    "\n",
    "del df_circle_val \n",
    "del list_of_coords_val \n",
    "del images_val  \n",
    "del list_of_prob_val \n",
    "\n",
    "del transformed_coords_test \n",
    "del transformed_probs_test \n",
    "del transformed_coords_train \n",
    "del transformed_probs_train \n",
    "del transformed_coords_val \n",
    "del transformed_probs_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: make dataset smaller\n",
    "test_set_coords = test_set_coords[:40]\n",
    "test_set_img = test_set_img[:40]\n",
    "\n",
    "train_set_coords = train_set_coords[:300]\n",
    "train_set_img = train_set_img[:300]\n",
    "\n",
    "valid_set_coords = valid_set_coords[:40]\n",
    "valid_set_img = valid_set_img[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n",
      "896\n",
      "7168\n",
      "7168\n",
      "896\n",
      "896\n"
     ]
    }
   ],
   "source": [
    "print(len(test_set_coords))\n",
    "print(len(test_set_img))\n",
    "print(len(train_set_coords))\n",
    "print(len(train_set_img))\n",
    "print(len(valid_set_coords))\n",
    "print(len(valid_set_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "model = load_model(\n",
    "    r'<your_file_path>',\n",
    "    compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of mAP for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór treningowy\n",
      "Średnia mAP: 17.39686176341071 %\n"
     ]
    }
   ],
   "source": [
    "# Define the grid size for object detection\n",
    "grid_size = (7, 10)\n",
    "\n",
    "# Initialize an empty dataset to store ground truth and prediction coordinates\n",
    "dataset = []\n",
    "\n",
    "# Define the dataset to use (e.g., the training dataset)\n",
    "subset_img  = train_set_img  # Input image dataset\n",
    "subset_coords = train_set_coords  # Corresponding ground truth coordinates\n",
    "\n",
    "# Iterate through each image to calculate mean Average Precision (mAP)\n",
    "for i in range(len(subset_coords)):\n",
    "    # Reshape the input image for model prediction\n",
    "    input_image_reshaped = np.expand_dims(subset_img[i], axis=0)\n",
    "    \n",
    "    # Obtain predictions from the model\n",
    "    predictions = model.predict(input_image_reshaped, verbose=0)\n",
    "    \n",
    "    # Concatenate predictions from two sources (potentially different aspects of detection)\n",
    "    predictions = np.concatenate((predictions[0], predictions[1]), axis=4)\n",
    "    \n",
    "    # Reverse transform and normalize the predictions to the original format\n",
    "    dt, probab = reverse_transform_data_and_normalization(predictions, grid_size)\n",
    "    \n",
    "    # Reverse transform ground truth coordinates to the original format and normalize them\n",
    "    test_set_coords_tr = reverse_transform_deep_nested_coords_and_normalization([subset_coords[i]], grid_size, max_box_per_apple=1)\n",
    "    \n",
    "    # Apply a threshold to predictions and split them into separate elements\n",
    "    prediction = apply_threshold_and_split_pred(dt, 0)\n",
    "    \n",
    "    # Collect predictions before non-maximum suppression (NMS) operation\n",
    "    before_nms = []\n",
    "    for list_ in prediction:\n",
    "        for elem in list_:\n",
    "            before_nms.append(elem)\n",
    "    \n",
    "    # Apply non-maximum suppression (NMS) operation to filter out redundant predictions\n",
    "    pred_after_nms = NMS(before_nms, 0.7, 0.5, probab[0])\n",
    "    \n",
    "    # Extract only the prediction coordinates after NMS (excluding probabilities)\n",
    "    only_pred_after_nms = []\n",
    "    for list_ in pred_after_nms:\n",
    "        only_pred_after_nms.append(list_[:-1])\n",
    "    \n",
    "    # Split the original ground truth coordinates\n",
    "    original_coords = split_origin(test_set_coords_tr)\n",
    "    \n",
    "    # Remove coordinates with confidence score less than or equal to zero\n",
    "    original_coords_without_zeros = []\n",
    "    for elem in original_coords:\n",
    "        if elem[-1] > 0:\n",
    "            original_coords_without_zeros.append(elem)\n",
    "    \n",
    "    # Append ground truth and filtered prediction coordinates to the dataset\n",
    "    dataset.append((original_coords_without_zeros, only_pred_after_nms))\n",
    "\n",
    "# Calculate the mean Average Precision (mAP) for the dataset using various IoU thresholds\n",
    "mean_map = mean_average_precision(dataset, iou_thresholds=np.arange(0.5, 1.0, 0.05))\n",
    "\n",
    "\n",
    "mean_map = mean_average_precision(dataset, iou_thresholds=np.arange(0.5, 1.0, 0.05))\n",
    "print(\"Zbiór treningowy\")\n",
    "print(f\"Średnia mAP: {mean_map*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór walidacyjny\n",
      "Średnia mAP: 0.5512851071852903 %\n"
     ]
    }
   ],
   "source": [
    "grid_size = (7,10)\n",
    "dataset = []\n",
    "subset_img  = valid_set_img\n",
    "subset_coords = valid_set_coords\n",
    "\n",
    "for i in range(len(subset_coords)):\n",
    "    input_image_reshaped = np.expand_dims(subset_img[i], axis=0)\n",
    "    predictions=model.predict(input_image_reshaped, verbose = 0)\n",
    "    predictions = np.concatenate((predictions[0], predictions[1]), axis = 4)\n",
    "    dt, probab = reverse_transform_data_and_normalization(predictions, grid_size)\n",
    "    test_set_coords_tr = reverse_transform_deep_nested_coords_and_normalization([subset_coords[i]], grid_size, max_box_per_apple=1)\n",
    "    prediction = apply_threshold_and_split_pred(dt, 0)\n",
    "    before_nms = []\n",
    "    for list_ in prediction:\n",
    "        for elem in list_:\n",
    "            before_nms.append(elem)\n",
    "    pred_after_nms = NMS(before_nms,0.7,0.5,probab[0])\n",
    "    only_pred_after_nms = []\n",
    "    for list_ in pred_after_nms:\n",
    "        only_pred_after_nms.append(list_[:-1])\n",
    "    original_coords = split_origin(test_set_coords_tr)\n",
    "    original_coords_without_zeros = []\n",
    "    for elem in original_coords:\n",
    "        if elem[-1] > 0:\n",
    "            original_coords_without_zeros.append(elem)\n",
    "    dataset.append((original_coords_without_zeros,only_pred_after_nms))\n",
    "\n",
    "\n",
    "mean_map = mean_average_precision(dataset, iou_thresholds=np.arange(0.5, 1.0, 0.05))\n",
    "print(\"Zbiór walidacyjny\")\n",
    "print(f\"Średnia mAP: {mean_map*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór testowy\n",
      "Średnia mAP: 0.6195908812143605 %\n"
     ]
    }
   ],
   "source": [
    "grid_size = (7,10)\n",
    "dataset = []\n",
    "subset_img  = test_set_img\n",
    "subset_coords = test_set_coords\n",
    "\n",
    "for i in range(len(subset_coords)):\n",
    "    input_image_reshaped = np.expand_dims(subset_img[i], axis=0)\n",
    "    predictions=model.predict(input_image_reshaped, verbose = 0)\n",
    "    predictions = np.concatenate((predictions[0], predictions[1]), axis = 4)\n",
    "    dt, probab = reverse_transform_data_and_normalization(predictions, grid_size)\n",
    "    test_set_coords_tr = reverse_transform_deep_nested_coords_and_normalization([subset_coords[i]], grid_size, max_box_per_apple=1)\n",
    "    prediction = apply_threshold_and_split_pred(dt, 0)\n",
    "    before_nms = []\n",
    "    for list_ in prediction:\n",
    "        for elem in list_:\n",
    "            before_nms.append(elem)\n",
    "    pred_after_nms = NMS(before_nms,0.7,0.5,probab[0])\n",
    "    only_pred_after_nms = []\n",
    "    for list_ in pred_after_nms:\n",
    "        only_pred_after_nms.append(list_[:-1])\n",
    "    original_coords = split_origin(test_set_coords_tr)\n",
    "    original_coords_without_zeros = []\n",
    "    for elem in original_coords:\n",
    "        if elem[-1] > 0:\n",
    "            original_coords_without_zeros.append(elem)\n",
    "    dataset.append((original_coords_without_zeros,only_pred_after_nms))\n",
    "\n",
    "\n",
    "\n",
    "mean_map = mean_average_precision(dataset, iou_thresholds=np.arange(0.5, 1.0, 0.05))\n",
    "print(\"Zbiór testowy\")\n",
    "print(f\"Średnia mAP: {mean_map*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
